# Exploraci√≥n del Playground del Servicio OCI Generativa AI

## Introducci√≥n

> La IA Generativa est√° transformando la forma en que navegamos y utilizamos el conocimiento, desde la s√≠ntesis de datos complejos hasta la creaci√≥n de respuestas contextuales. Con Oracle Cloud Infrastructure (OCI), incorporar funcionalidades de IA generativa nunca ha sido tan accesible.

<br>
### ‚≠ï **¬øQu√© es la Inteligencia Artificial Generativa?**

La Inteligencia Artificial Generativa es una tecnolog√≠a de IA que crea nuevos contenidos, como textos, im√°genes y videos, a partir de datos de entrenamiento. En lugar de solo analizar datos, produce contenidos originales, simulando la creatividad humana.

| Capacidad          | Ejemplos de Aplicaciones                          |
|--------------------|--------------------------------------------------|
| Creaci√≥n de Contenido | Textos, im√°genes, videos, audio                  |
| Asistencia         | Atenci√≥n al cliente, asistentes virtuales        |
| Innovaci√≥n         | Dise√±o de productos, investigaci√≥n y desarrollo  |
{: title=" "}

<br>
### ‚≠ï **¬øPor qu√© es importante la Inteligencia Artificial Generativa?**

La IA Generativa automatiza tareas creativas y cognitivas, lo que puede:
- **Aumentar la productividad**: Generaci√≥n r√°pida de contenido personalizado.
- **Impulsar la innovaci√≥n**: Herramientas para experimentaci√≥n y desarrollo √°gil.
- **Mejorar la experiencia del cliente**: Respuestas e interacciones m√°s naturales.

<br>
### ‚≠ï **¬øQu√© es el Servicio de IA Generativa de OCI?**

El [**OCI Generative AI**](https://www.oracle.com/artificial-intelligence/generative-ai/large-language-models/) es un servicio gestionado que ofrece acceso a modelos de IA Generativa, como Llama 3.1 y Cohere Command R. Permite explorar e integrar IA generativa para diversos casos de uso, de manera escalable y segura.

Este servicio ofrece una forma pr√°ctica de incorporar IA Generativa, sin necesidad de gestionar infraestructura compleja. El servicio posibilita experimentaci√≥n r√°pida e integraciones directas para facilitar el desarrollo de soluciones inteligentes y personalizadas. Modelos disponibles:

| Modelo              | Descripci√≥n                                                                                             | Principales Caracter√≠sticas                              | Idiomas Soportados |
|---------------------|---------------------------------------------------------------------------------------------------------|----------------------------------------------------------|---------------------|
| **Cohere Command R**   | Modelo optimizado para aplicaciones de **retrieval-augmented generation (RAG)**.                         | Alta eficiencia, baja latencia, mayor ventana de contexto | 10 idiomas          |
| **Cohere Command R+**  | Versi√≥n mejorada del Command R para **casos de uso especializados** como generaci√≥n de contenido largo. | Genera respuestas contextuales y detalladas               | 10 idiomas          |
| **Cohere Embed**       | Modelos de embeddings para **convertir texto en representaciones vectoriales**.                       | Las versiones "Light" son m√°s peque√±as y r√°pidas          | Ingl√©s y Multiling√ºe |
| **Meta Llama 3.1**     | Modelos open source de √∫ltima generaci√≥n con **alto rendimiento y diversidad de respuestas**.          | Ventana de contexto de 128K y soporte para 8 idiomas      | 8 idiomas           |
{: title=" "}

### **Objetivos**

En este workshop, aprender√°s a explorar los modelos de IA Generativa de OCI, basados en grandes modelos de lenguaje (LLMs). Aunque es posible integrar el servicio v√≠a APIs REST, permitiendo que incorpores esta tecnolog√≠a avanzada en tus soluciones de manera pr√°ctica y eficiente, en este laboratorio usaremos el **playground** del servicio de IA Generativa en OCI. El playground ofrece una forma pr√°ctica e interactiva de experimentar los recursos de IA generativa, sin necesidad de configuraciones para integrar la funcionalidad a otros servicios.

El laboratorio se dividir√° en tres etapas, explorando diferentes aspectos de LLMs e IA Generativa:

1. **Embeddings**: Comprender c√≥mo los embeddings se utilizan para representar y buscar informaci√≥n de manera eficiente.
2. **Generaci√≥n de Texto**: Aprender a generar textos personalizados y contextuales para diversos casos de uso.
3. **Simulaci√≥n de Flujo de RAG (Retrieval-Augmented Generation)**: Ver c√≥mo integrar la recuperaci√≥n de informaci√≥n con generaci√≥n de texto para crear respuestas contextuales a partir de datos espec√≠ficos.

<br>
### **Recursos y Soporte**:

- **Documentaci√≥n de Oracle Cloud**: [¬øQu√© es la Inteligencia Artificial Generativa?](https://www.oracle.com/br/artificial-intelligence/generative-ai/what-is-generative-ai/)
- **Tutoriales**: Explora el [Centro de Aprendizaje de Oracle](https://mylearn.oracle.com/ou/home)


### _**¬°Disfruta tu experiencia en Oracle Cloud!**_


## Tarea 1: Modelos de Embeddings

### ‚≠ï **¬øQu√© son los Embeddings?**
> Los embeddings son representaciones vectoriales de objetos, como textos o im√°genes. **Al transformar objetos en vectores, podemos realizar operaciones matem√°ticas que permiten comparar, analizar y calcular la similitud entre ellos.** Esto posibilita, por ejemplo, identificar semejanzas entre textos o buscar informaci√≥n relevante de manera eficaz.

### üîç **¬øPor qu√© son importantes los Embeddings?**
   - **An√°lisis de Similitud:** Con embeddings, podemos calcular la proximidad entre diferentes objetos, facilitando la identificaci√≥n de √≠tems similares.
   - **Eficiencia Computacional:** Representar datos en vectores hace que el procesamiento de informaci√≥n sea m√°s r√°pido y eficiente.
   - **Versatilidad:** Los embeddings se pueden utilizar en varios contextos, como b√∫squeda de informaci√≥n, recomendaci√≥n de contenido, entre otros.

### <span style="background-color:#FFFFE0;">**Paso 1.**</span>

Acceder al Servicio de OCI Generative AI. La forma m√°s sencilla de hacer esto es buscando por **‚ÄúGenerative AI‚Äù** en la barra de b√∫squeda:

   ![Search Generative AI](images/search-genai.png " ")

Una vez dentro del servicio, seleccionaremos **‚ÄúEmbedding‚Äù**, en el men√∫ del lado izquierdo, debajo de **‚ÄúPlayground‚Äù**.

   ![Acess Playground](images/genai-playground-acess.png " ")

### <span style="background-color:#FFFFE0;">**Paso 2.**</span>

Dentro del Playground, vamos a la caja de selecci√≥n ‚Äúmodel‚Äù y seleccionamos el modelo **cohere.embed-multilingual-v3**, luego, a√±adimos las frases a continuaci√≥n en las cajas blancas disponibles. No es necesario que est√©n en orden:

    <copy>
    Los perros son animales incre√≠bles.
    </copy>
<!-- Separador -->

    <copy>  
    Amo a los perros, son fant√°sticos.  
    </copy>  
<!-- Separador -->

    <copy>  
    A los perros les encanta jugar al aire libre y correr por el parque.  
    </copy>  
<!-- Separador -->

    <copy>  
    Los gatos son animales elegantes y misteriosos.  
    </copy>  
<!-- Separador -->

    <copy>  
    Los gatos son expertos en encontrar los mejores lugares para dormir.  
    </copy>  
<!-- Separador -->

    <copy>  
    Los gatos tienen una habilidad incre√≠ble para colarse en espacios peque√±os.  
    </copy>  
<!-- Separador -->

    <copy>  
    Porsche fabrica coches hermosos.  
    </copy>  
<!-- Separador -->

    <copy>  
    Ferrari es conocida por sus coches r√°pidos.  
    </copy>  
<!-- Separador -->

    <copy>  
    Los coches deportivos son para quienes buscan emoci√≥n en la carretera.  
    </copy>  
<!-- Separador -->

    <copy>  
    A los gatos les gusta esconderse en coches deportivos, como en un Ferrari.  
    </copy>  
<!-- Separador -->

    <copy>  
    A los perros les encanta disfrutar del viento mientras pasean en coches descapotables, como un Porsche.  
    </copy>  

![Embeddings](images/embeddings.png " ")

Luego, haz clic en **Run**.

![Embeddings Response](images/embeddings-response.png " ")

### <span style="background-color:#FFFFE0;">**Paso 3.**</span>

> **Los vectores de embeddings suelen tener muchas dimensiones (generalmente, entre 512 y 1024 dimensiones). Como es imposible visualizar gr√°ficamente algo con tantas dimensiones, lo que se suele hacer es una ‚ÄúProyecci√≥n‚Äù de estos vectores multidimensionales en superficies bidimensionales, permitiendo la visualizaci√≥n.**

La proximidad entre los vectores en el gr√°fico representa la **similitud sem√°ntica entre las frases.** Cuanto m√°s cercanos est√©n dos puntos, m√°s similares son las frases en t√©rminos de contenido y contexto, seg√∫n el modelo de embedding.

Por ejemplo:
   - **Vectores 1, 2, 3, 4, 5 y 6:** Las frases sobre caracter√≠sticas y comportamientos de gatos y perros est√°n agrupadas, reflejando similitudes relacionadas con los animales y sus acciones t√≠picas.
   - **Vectores 7, 8 y 9:** Las frases que mencionan coches deportivos y marcas como Ferrari y Porsche est√°n pr√≥ximas entre s√≠, ya que comparten temas de autom√≥viles y experiencias de conducci√≥n.
   - **Vectores 10 y 11:** Las frases sobre "gato y Ferrari" y "perro y Porsche" est√°n pr√≥ximas entre s√≠ y de los cl√∫steres de coches de lujo, ya que combinan comportamientos de mascotas con autom√≥viles, uniendo ambos temas.

## Tarea 2: Modelos de Generaci√≥n de Texto

### ‚≠ï **¬øQu√© son 'Tokens' y 'Par√°metros' en Modelos de Generaci√≥n de Texto?**
> **Tokens** son unidades de texto, como palabras, partes de palabras,

 o incluso caracteres, que el modelo utiliza para construir frases. En lugar de generar una frase entera de una vez, el modelo procesa el texto eligiendo un token a la vez, siguiendo una secuencia hasta formar la respuesta completa.
<br><br>
> **Par√°metros** ajustan la forma en que el modelo decide el pr√≥ximo token, permitiendo un equilibrio entre creatividad y coherencia en la generaci√≥n de texto.


| **Par√°metros**       | **Descripci√≥n**                                                                                                                                                                                                                                    | **Ejemplo**             |
|---------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------|
| **Temperatura**   | Controla la aleatoriedad en la generaci√≥n del texto. Valores bajos hacen que el texto sea m√°s directo y predecible, mientras que valores altos hacen que el texto sea m√°s creativo e inesperado, pudiendo afectar la coherencia.                                           | Baja (0.2) = "El coche es rojo y r√°pido." <br> Alta (0.8) = "El coche es rojo, veloz y parece un cohete." |
| **Top-p** (N√∫cleo) | Limita las opciones del modelo a los tokens m√°s probables hasta que la suma de sus probabilidades alcance un cierto porcentaje. Esto mantiene el control sobre la variabilidad del texto, evitando opciones improbables.                                    | Top-p = 0.9 considera los tokens m√°s probables que suman 90% de la probabilidad total, enfoc√°ndose en las opciones m√°s probables. |
| **Top-k**          | Restringe la elecci√≥n a los k tokens m√°s probables, lo que ayuda a mantener el texto coherente y enfocado al seleccionar entre las opciones m√°s probables, seg√∫n el l√≠mite determinado.                                                              | Top-k = 50 limita la elecci√≥n a los 50 tokens m√°s probables, restringiendo la variabilidad para mayor coherencia. |
{: title=" "}

### <span style="background-color:#FFFFE0;">**Paso 4.**</span>

> **Ahora, vamos a analizar c√≥mo se comporta el modelo en la generaci√≥n de texto, enfoc√°ndonos especialmente en la influencia del par√°metro Temperatura. En la generaci√≥n de texto, existen varios otros par√°metros que influyen en la elecci√≥n de cada palabra (o token). Para ello, probaremos diferentes combinaciones de estos par√°metros en varios escenarios de generaci√≥n de texto.**

Una vez dentro del servicio, seleccionaremos **‚ÄúChat‚Äù**, en el men√∫ del lado izquierdo, debajo de **‚ÄúPlayground‚Äù**. 

![Chat](images/chat.png " ")

En la pantalla indicada a continuaci√≥n, selecciona el modelo **cohere.command-r-plus v1.2**. A√±ade el siguiente prompt al chat, en la regi√≥n inferior de la pantalla y haz clic en **Submit**:

    <copy>
    Escribe un p√°rrafo sobre los beneficios del uso de inteligencia artificial en el sector de la salud, enfoc√°ndote en c√≥mo la IA puede mejorar el diagn√≥stico y tratamiento de enfermedades. Explica de manera clara y objetiva, destacando ejemplos pr√°cticos de aplicaci√≥n y los posibles impactos positivos en la vida de los pacientes.
    </copy>

![Chat Submit](images/chat-submit.png " ")

### <span style="background-color:#FFFFE0;">**Paso 5.**</span>

> **Inicialmente, estamos generando una respuesta utilizando los par√°metros predeterminados. Una vez generada la respuesta, vamos a repetir con el mismo prompt, ajustando los par√°metros. ¬øQu√© piensas que podr√≠a pasar?**

**Ejemplo 1:** La temperatura est√° alta (1), permitiendo una respuesta m√°s creativa y variada, pero a√∫n coherente. Top-k es cero, sin limitaci√≥n en la cantidad de tokens m√°s probables, permitiendo opciones m√°s amplias.

![Temperature](images/temperature.png " ")

**Ejemplo 2:** La temperatura est√° baja (0.25), generando un texto m√°s predecible y seguro. Top-k est√° en 500, dando una amplia variedad de opciones, pero la baja temperatura mantiene el texto directo y menos creativo.

![Top k](images/topk.png " ")

**Ejemplo 3:** La temperatura fue elevada a 2, lo que result√≥ en una respuesta menos coherente con repeticiones aleatorias. Top-p est√° muy bajo (0.05), restringiendo las opciones y llevando a una respuesta poco √∫til. La combinaci√≥n de estos valores genera inestabilidad en el texto.

![Top p & temperature](images/top-p-temperature.png " ")

## Tarea 3: Simulando un Flujo de RAG

### ‚≠ï **¬øQu√© es Retrieval-Augmented Generation (RAG)?**
> Retrieval-Augmented Generation (RAG) es una t√©cnica que combina modelos generativos con sistemas de recuperaci√≥n de informaci√≥n. **Al incorporar una etapa de recuperaci√≥n, RAG permite que el modelo de IA acceda a datos espec√≠ficos antes de generar una respuesta, integrando informaci√≥n relevante en el contexto del usuario.** Esto ayuda a reducir las alucinaciones y mejora la precisi√≥n de las respuestas, especialmente en dominios especializados.

### üîç **¬øPor qu√© es importante RAG en Aplicaciones Empresariales?**
   - **Precisi√≥n Aumentada:** RAG consulta fuentes de datos espec√≠ficas, lo que reduce la probabilidad de respuestas incorrectas o alucinaciones.
   - **Ahorro de Recursos:** No requiere fine-tuning del modelo para cada dominio, ya que el conocimiento especializado se recupera en tiempo real.
   - **Aplicaciones Empresariales Eficientes:** RAG es ideal para empresas que necesitan respuestas precisas basadas en datos internos, permitiendo que el modelo acceda a informaci√≥n sensible o propietaria.

### üîç **Configuraci√≥n de Par√°metros para RAG**  
En un sistema de RAG, queremos que el modelo devuelva solo la informaci√≥n presente en el contexto fijo, evitando respuestas fuera del alcance. Para ello, utilizaremos una configuraci√≥n m√°s conservadora:

| **Par√°metro**    | **Configuraci√≥n**   | **Descripci√≥n**                                                                                  |
|------------------|----------------------|--------------------------------------------------------------------------------------------------|
| **Temperatura**  | 0.1                  | Garantiza respuestas m√°s predecibles y menos creativas.                                          |
| **Top-p**        | 0.95                 | Incluye el 95% de los tokens m√°s probables, equilibrando precisi√≥n con cierta variabilidad.       |
| **Top-k**        | 20                   | Limita las opciones a los 20 tokens m√°s probables, aumentando la coherencia en las respuestas.    |
{: title=" "}

### ‚≠ï **¬øQu√© es un Prompt?**

> Un **prompt** es una instrucci√≥n o pregunta dada a un modelo de IA para guiar la generaci√≥n de respuestas o contenido espec√≠fico.

Para asegurar buenos resultados, el prompt debe incluir:  
   - **Persona:** Define el perfil de quien responde.
   - **Descripci√≥n de la Tarea:** Explica lo que el modelo debe hacer.
   - **Instrucciones de Formato:** Detalla el formato esperado de la respuesta.
   - **Contexto:** Informaci√≥n relevante (extra√≠da de documentos o sistemas).
   - **Pregunta:** Cuesti√≥n espec√≠fica a responder.

| **Ejemplo de Prompt** |
|-----------------------|
| Eres un experto en Inteligencia Artificial y debes responder preguntas sobre los servicios OCI Speech y OCI Language de Oracle. Responde solo en espa√±ol, de forma directa y basada en el contexto proporcionado. No inventes informaci√≥n que no est√© en el contexto, ya que esto es crucial para mi carrera.<br> **Pregunta:** (Agrega aqu√≠ tu pregunta) <br> **Contexto:** (Pega aqu√≠ el contexto de la informaci√≥n) | 

### <span style="background-color:#FFFFE0;">**Paso 6.**</span>

> **En esta tarea, vamos a simular un flujo de RAG en el Playground para ver c√≥mo prompts dirigidos pueden extraer informaci√≥n espec√≠fica de un dominio. La idea es explorar c√≥mo RAG puede integrar datos relevantes directamente en el proceso de generaci√≥n de texto, mejorando la precisi√≥n y relevancia de las respuestas.**

Una vez dentro del servicio, seleccionaremos **‚ÄúChat‚Äù**, en el men√∫ del lado izquierdo, debajo de **‚ÄúPlayground‚Äù**. 

![Chat](images/chat.png " ")

En la pantalla indicada a continuaci√≥n, selecciona el modelo **cohere.command-r-plus v1.2**. A√±ade el siguiente prompt al chat, en la regi√≥n inferior de la pantalla y haz clic en **Submit**:

    <copy>
    Eres un experto en Inteligencia Artificial, y debes responder preguntas sobre dos de los servicios que ofrece Oracle, OCI Speech y OCI Language. Responde solo en espa√±ol y de forma directa y resumida, bas√°ndote solo en el contexto proporcionado. Si no es posible construir una respuesta, no intentes inventar informaci√≥n que no est√© en el contexto. Responde con atenci√≥n, pues esto es muy importante para mi carrera.

    Contexto: OCI Speech admite 12 formatos de audio, incluidos el formato OGG (formato de audio de WhatsApp), adem√°s de los m√°s comunes como MP3 y WAV. Tambi√©n admite videos en formato MP4.
    Speech admite 10 idiomas diferentes, incluidos 4 tipos de ingl√©s (estadounidense, brit√°nico, australiano e indio), adem√°s de espa√±ol, portugu√©s, alem√°n y otros. La transcripci√≥n tambi√©n incluye puntuaci√≥n y se puede realizar en formato SRT.
    
    OCI Language es un servicio gestionado de inteligencia artificial enfocado en actividades de an√°lisis de texto y procesamiento de lenguaje natural. Un punto importante: Language no es una herramienta de IA Generativa. Su objetivo es realizar an√°lisis extractivos sobre textos.
    Nativamente, los modelos preentrenados de OCI Language son capaces de realizar las siguientes tareas: Clasificaci√≥n de textos en cientos de categor√≠as; Detecci√≥n de idioma con docenas de opciones; Extracci√≥n de docenas de Entidades Nombradas diferentes; Extracci√≥n de frases clave; An√°lisis y detecci√≥n de sentimientos; Detecci√≥n y enmascaramiento de docenas de datos personales; Traducci√≥n con soporte para varios idiomas.

    Pregunta: ¬øQu√© funcionalidades admite OCI Language?
    </copy>

![Chat](images/rag.png " ")

### <span style="background-color:#FFFFE0;">**Paso 7.**</span>

Es muy interesante probar la pregunta con y sin el contexto proporcionado, y evaluar el comportamiento del modelo para cada ejemplo. Haz clic en **"Clear Chat"** y ¬°pru√©balo t√∫ mismo! 
Algunas sugerencias de preguntas:
> -	**¬øQu√© idiomas admite OCI Speech?**
> - **¬øQu√© funcionalidades ofrece OCI Language?**
> -	**¬øQu√© formatos de audio admite OCI Speech?**

 ![Chat No Context](images/rag-no-context.png " ")